{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "ch2_nb1_mnist_keras.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNdU7q5STsTI"
      },
      "source": [
        "본 ipynb 파일은 초기 제공 코드를 한국어 주석만 추가하고 분석한 파일로, 원본 파일이 더 자세히 적혀있고 의역이 있을 수 있다.\n",
        "\n",
        "원본 파일 : ch2_nb1_mnist_keras.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-16T11:43:45.756874Z",
          "start_time": "2019-05-16T11:43:44.798323Z"
        },
        "collapsed": true,
        "id": "LasG_VjuTsTJ"
      },
      "source": [
        "import tensorflow as tf # 텐서플로 임포트"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQMWlJ6nTsTK"
      },
      "source": [
        "## Input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-16T11:43:46.132993Z",
          "start_time": "2019-05-16T11:43:45.757994Z"
        },
        "collapsed": true,
        "id": "QuUstlxkTsTK"
      },
      "source": [
        "num_classes = 10 # 클래스 개수 (0~9)\n",
        "img_rows, img_cols = 28, 28 # 이미지 사이즈(가로, 세로 )\n",
        "num_channels = 1 # 흑백\n",
        "input_shape = (img_rows, img_cols, num_channels)\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # 값 정규화(0~1사이)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LNgs3HDTsTK"
      },
      "source": [
        "## Building a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-16T11:43:46.150349Z",
          "start_time": "2019-05-16T11:43:46.134258Z"
        },
        "collapsed": true,
        "id": "h6wsSnAiTsTL"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jClYWn64TsTL"
      },
      "source": [
        "## Launch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T13:52:39.124524Z",
          "start_time": "2019-05-14T13:51:49.141572Z"
        },
        "id": "uIO-sDvOTsTL",
        "outputId": "434d4221-c972-4913-c557-07dc21c3c8af"
      },
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "callbacks = [tf.keras.callbacks.TensorBoard('./keras')]\n",
        "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.6397 - accuracy: 0.8418 - val_loss: 0.3560 - val_accuracy: 0.9042\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3369 - accuracy: 0.9059 - val_loss: 0.2958 - val_accuracy: 0.9187\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2899 - accuracy: 0.9183 - val_loss: 0.2651 - val_accuracy: 0.9241\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2603 - accuracy: 0.9262 - val_loss: 0.2417 - val_accuracy: 0.9316\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2378 - accuracy: 0.9330 - val_loss: 0.2222 - val_accuracy: 0.9359\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2192 - accuracy: 0.9384 - val_loss: 0.2074 - val_accuracy: 0.9405\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2029 - accuracy: 0.9436 - val_loss: 0.1947 - val_accuracy: 0.9450\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1892 - accuracy: 0.9469 - val_loss: 0.1814 - val_accuracy: 0.9479\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1771 - accuracy: 0.9505 - val_loss: 0.1719 - val_accuracy: 0.9502\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1668 - accuracy: 0.9528 - val_loss: 0.1627 - val_accuracy: 0.9532\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1574 - accuracy: 0.9554 - val_loss: 0.1559 - val_accuracy: 0.9542\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.1491 - val_accuracy: 0.9560\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1420 - accuracy: 0.9599 - val_loss: 0.1439 - val_accuracy: 0.9581\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1352 - accuracy: 0.9622 - val_loss: 0.1382 - val_accuracy: 0.9597\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1292 - accuracy: 0.9639 - val_loss: 0.1335 - val_accuracy: 0.9615\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1236 - accuracy: 0.9657 - val_loss: 0.1286 - val_accuracy: 0.9626\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1186 - accuracy: 0.9668 - val_loss: 0.1245 - val_accuracy: 0.9628\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1135 - accuracy: 0.9684 - val_loss: 0.1223 - val_accuracy: 0.9645\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1095 - accuracy: 0.9697 - val_loss: 0.1172 - val_accuracy: 0.9648\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1053 - accuracy: 0.9713 - val_loss: 0.1153 - val_accuracy: 0.9663\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1017 - accuracy: 0.9717 - val_loss: 0.1128 - val_accuracy: 0.9670\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0983 - accuracy: 0.9725 - val_loss: 0.1095 - val_accuracy: 0.9681\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0949 - accuracy: 0.9735 - val_loss: 0.1066 - val_accuracy: 0.9693\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0917 - accuracy: 0.9747 - val_loss: 0.1054 - val_accuracy: 0.9695\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0891 - accuracy: 0.9758 - val_loss: 0.1040 - val_accuracy: 0.9696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9c242a3c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyKthdeITsTM"
      },
      "source": [
        "## Running with an estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-29T11:04:31.961895Z",
          "start_time": "2019-04-29T11:04:31.956592Z"
        },
        "id": "ITuXU9uwTsTM",
        "outputId": "bde26c4d-aa03-43d2-acc6-429d76b3b1a3"
      },
      "source": [
        "estimator = tf.keras.estimator.model_to_estimator(model, model_dir='./estimator_dir')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0429 13:04:31.959720 140496034522880 keras.py:460] You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
            "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-04-29T11:05:35.649548Z",
          "start_time": "2019-04-29T11:04:32.510795Z"
        },
        "id": "gr17SEWzTsTN",
        "outputId": "ac012f44-dc30-4641-bc3a-d1a2a2e42968"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "def train_input_fn():\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE).repeat()\n",
        "    return train_dataset\n",
        "\n",
        "estimator.train(train_input_fn, steps=len(x_train)//BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fc6e40b3160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}